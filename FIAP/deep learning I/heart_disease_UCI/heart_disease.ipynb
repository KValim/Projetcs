{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "Fonte: https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data\n",
    "\n",
    "## Descrição das colunas\n",
    "\n",
    "**age**: (Age of the patient in years)\n",
    "\n",
    "**sex**: (Male/Female)\n",
    "\n",
    "**cp**: chest pain type ([typical angina, atypical angina, non-anginal, asymptomatic])\n",
    "\n",
    "**trestbps**: resting blood pressure (resting blood pressure (in mm Hg on admission to the hospital))\n",
    "\n",
    "**chol**: (serum cholesterol in mg/dl)\n",
    "\n",
    "**fbs**: (if fasting blood sugar > 120 mg/dl)\n",
    "\n",
    "**restecg**: (resting electrocardiographic results): [normal, stt abnormality, lv hypertrophy]\n",
    "\n",
    "**thalach**: maximum heart rate achieved\n",
    "\n",
    "**exang**: exercise-induced angina (True/ False)\n",
    "\n",
    "**oldpeak**: ST depression induced by exercise relative to rest\n",
    "\n",
    "**slope**: the slope of the peak exercise ST segment\n",
    "\n",
    "**ca**: number of major vessels (0-3) colored by fluoroscopy\n",
    "\n",
    "**thal**: [normal; fixed defect; reversible defect]\n",
    "\n",
    "**num**: the predicted attribute\n",
    "\n",
    "\n",
    "## Comentários Iniciais\n",
    "\n",
    "O dataset fornecido pelo professor já veio com o procedo de *Feature Engineering* executado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bicliotecas e Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/KValim/Projetcs/main/FIAP/deep%20learning%20I/heart_disease_UCI/heart.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "corr = df.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=8),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nenhuma correlação expressiva em relação a variável target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split it into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X (features) and y (target)\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then standardize the data using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will build our MLP neural network using Keras. We will start by defining the model as a Sequential model, and then adding two hidden layers with 64 and 32 units respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the hidden layers\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=32, activation='relu'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will add the output layer with a sigmoid activation function, and compile the model using the Adam optimizer and binary crossentropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_43 (Dense)            (None, 64)                896       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,009\n",
      "Trainable params: 3,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model, we will use the fit method, passing in our training data and labels, and specifying the number of epochs and the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.6620 - accuracy: 0.6116\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.5832 - accuracy: 0.7975\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.5210 - accuracy: 0.8099\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.4713 - accuracy: 0.8388\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.4291 - accuracy: 0.8430\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.3970 - accuracy: 0.8471\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.3697 - accuracy: 0.8760\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3504 - accuracy: 0.8802\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8802\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.3204 - accuracy: 0.8802\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 986us/step - loss: 0.3107 - accuracy: 0.8843\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3004 - accuracy: 0.8843\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2928 - accuracy: 0.8843\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2851 - accuracy: 0.8843\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2789 - accuracy: 0.8843\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2717 - accuracy: 0.8843\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.2659 - accuracy: 0.8884\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2607 - accuracy: 0.8884\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.2560 - accuracy: 0.8926\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2508 - accuracy: 0.8926\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 859us/step - loss: 0.2450 - accuracy: 0.8967\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2397 - accuracy: 0.9050\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2344 - accuracy: 0.9050\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 852us/step - loss: 0.2291 - accuracy: 0.9091\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.2251 - accuracy: 0.9091\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 934us/step - loss: 0.2212 - accuracy: 0.9298\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2152 - accuracy: 0.9215\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2107 - accuracy: 0.9298\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2063 - accuracy: 0.9339\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 956us/step - loss: 0.2017 - accuracy: 0.9380\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.1981 - accuracy: 0.9380\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.1944 - accuracy: 0.9421\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 864us/step - loss: 0.1905 - accuracy: 0.9421\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.1860 - accuracy: 0.9421\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1814 - accuracy: 0.9421\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1773 - accuracy: 0.9421\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1723 - accuracy: 0.9421\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1696 - accuracy: 0.9421\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1658 - accuracy: 0.9463\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 920us/step - loss: 0.1612 - accuracy: 0.9421\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1574 - accuracy: 0.9545\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1540 - accuracy: 0.9545\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1501 - accuracy: 0.9587\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.1470 - accuracy: 0.9587\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 859us/step - loss: 0.1430 - accuracy: 0.9669\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9669\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 941us/step - loss: 0.1365 - accuracy: 0.9669\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1325 - accuracy: 0.9711\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.1295 - accuracy: 0.9711\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1265 - accuracy: 0.9711\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.1235 - accuracy: 0.9752\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1202 - accuracy: 0.9793\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.1182 - accuracy: 0.9752\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 998us/step - loss: 0.1145 - accuracy: 0.9752\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.1120 - accuracy: 0.9752\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1093 - accuracy: 0.9793\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1062 - accuracy: 0.9793\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1037 - accuracy: 0.9835\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1015 - accuracy: 0.9793\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 877us/step - loss: 0.0988 - accuracy: 0.9835\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 983us/step - loss: 0.0962 - accuracy: 0.9835\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 882us/step - loss: 0.0933 - accuracy: 0.9835\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0911 - accuracy: 0.9835\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 859us/step - loss: 0.0899 - accuracy: 0.9835\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0869 - accuracy: 0.9835\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0849 - accuracy: 0.9835\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 859us/step - loss: 0.0827 - accuracy: 0.9835\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 895us/step - loss: 0.0806 - accuracy: 0.9835\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 992us/step - loss: 0.0789 - accuracy: 0.9835\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 977us/step - loss: 0.0767 - accuracy: 0.9835\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0749 - accuracy: 0.9835\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0736 - accuracy: 0.9876\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0716 - accuracy: 0.9876\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 856us/step - loss: 0.0698 - accuracy: 0.9876\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9876\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 919us/step - loss: 0.0667 - accuracy: 0.9876\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 985us/step - loss: 0.0650 - accuracy: 0.9876\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 859us/step - loss: 0.0635 - accuracy: 0.9876\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 859us/step - loss: 0.0620 - accuracy: 0.9876\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0604 - accuracy: 0.9876\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0586 - accuracy: 0.9876\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0577 - accuracy: 0.9876\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 994us/step - loss: 0.0563 - accuracy: 0.9876\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0554 - accuracy: 0.9876\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 902us/step - loss: 0.0536 - accuracy: 0.9876\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9876\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 945us/step - loss: 0.0511 - accuracy: 0.9876\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.9876\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0484 - accuracy: 0.9917\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.0466 - accuracy: 0.9917\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 994us/step - loss: 0.0458 - accuracy: 0.9917\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0449 - accuracy: 0.9917\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 851us/step - loss: 0.0438 - accuracy: 0.9917\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9917\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0412 - accuracy: 0.9917\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9917\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0392 - accuracy: 0.9917\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0381 - accuracy: 0.9917\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0373 - accuracy: 0.9917\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 994us/step - loss: 0.0366 - accuracy: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23c1190ef50>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can evaluate the model on the testing data using the evaluate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 998us/step - loss: 0.8930 - accuracy: 0.7869\n",
      "Loss: 0.8930461406707764\n",
      "Accuracy: 0.7868852615356445\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should give us a full code for classifying healthy or not healthy using an MLP neural network on the UCI Heart Disease dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 2\n",
    "A recurrent neural network (RNN) with one LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the LSTM layer\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[1], 1)))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 32)                4352      \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 4ms/step - loss: 0.6871 - accuracy: 0.6322\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6770 - accuracy: 0.6281\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6688 - accuracy: 0.6364\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6604 - accuracy: 0.6405\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.6405\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.6446\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.6446\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.6446\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.6529\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.6653\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.6777\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6818\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6983\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.7066\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.7025\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5845 - accuracy: 0.7107\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5752 - accuracy: 0.7231\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5620 - accuracy: 0.7355\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5522 - accuracy: 0.7438\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5400 - accuracy: 0.7397\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7314\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5248 - accuracy: 0.7190\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7273\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.7231\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7397\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7438\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7438\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.7438\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7521\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7562\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7521\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7521\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7479\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7521\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7479\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7438\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7479\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7562\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7438\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7603\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7645\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7521\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7521\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7521\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7645\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7686\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7727\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7686\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7810\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7769\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7851\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7769\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7810\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7769\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7769\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7851\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7893\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7893\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7934\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.8058\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8017\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7893\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.7893\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.7975\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.7934\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8140\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8099\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8182\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.8223\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8306\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8388\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8347\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3892 - accuracy: 0.8347\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8430\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3862 - accuracy: 0.8347\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8347\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8306\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3779 - accuracy: 0.8471\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8512\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.8430\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3708 - accuracy: 0.8471\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.8471\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8388\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8388\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3655 - accuracy: 0.8430\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8471\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3609 - accuracy: 0.8636\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8554\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8430\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8471\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8471\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8636\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8430\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.8512\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.8760\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8554\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8512\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8554\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3415 - accuracy: 0.8595\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23c12ac12a0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7245 - accuracy: 0.6557\n",
      "Loss: 0.7245498299598694\n",
      "Accuracy: 0.6557376980781555\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 3\n",
    "A hybrid neural network with one convolutional layer and one LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, LSTM\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the convolutional layer\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "\n",
    "# Add the LSTM layer\n",
    "model.add(LSTM(units=32))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 11, 32)            128       \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,481\n",
      "Trainable params: 8,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 4ms/step - loss: 0.6951 - accuracy: 0.5455\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.5537\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6751 - accuracy: 0.6281\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6658 - accuracy: 0.6529\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6548 - accuracy: 0.6777\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6427 - accuracy: 0.6942\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6265 - accuracy: 0.6860\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6102 - accuracy: 0.7273\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5843 - accuracy: 0.7397\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.7273\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.7686\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.8099\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7810\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7851\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7975\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.8058\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.8140\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.8058\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.8182\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.8017\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.8099\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8099\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8099\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8182\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8099\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8140\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8223\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8058\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8264\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8264\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8223\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3894 - accuracy: 0.8182\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8223\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8347\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8347\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8388\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8388\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8430\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8347\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8306\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8430\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.8306\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8512\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8471\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8347\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8554\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8471\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8471\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.8388\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.8471\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3527 - accuracy: 0.8430\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8554\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8554\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8471\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3384 - accuracy: 0.8595\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3379 - accuracy: 0.8636\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3372 - accuracy: 0.8595\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3380 - accuracy: 0.8636\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8636\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8636\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3305 - accuracy: 0.8595\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8595\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3183 - accuracy: 0.8595\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.8719\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.8595\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3094 - accuracy: 0.8760\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3010 - accuracy: 0.8884\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.8760\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8926\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2932 - accuracy: 0.8802\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.8554\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2875 - accuracy: 0.8884\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.9050\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.8884\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.8719\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2950 - accuracy: 0.8760\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.8843\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.8926\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3062 - accuracy: 0.8802\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2853 - accuracy: 0.8884\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2872 - accuracy: 0.8967\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2847 - accuracy: 0.8926\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.9050\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2939 - accuracy: 0.8760\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.8843\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2615 - accuracy: 0.9050\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2572 - accuracy: 0.9008\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2599 - accuracy: 0.9050\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.9174\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2590 - accuracy: 0.9050\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.9091\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.9132\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2594 - accuracy: 0.8926\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2561 - accuracy: 0.9132\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2354 - accuracy: 0.9132\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2395 - accuracy: 0.9256\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2482 - accuracy: 0.9256\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.9132\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.9050\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.9091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23c15f8e230>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7541\n",
      "Loss: 0.5034451484680176\n",
      "Accuracy: 0.7540983557701111\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nh=Ns(α∗(Ni+No))**\n",
    "\n",
    "\n",
    "Ni = number of input neurons.\n",
    "\n",
    "No = number of output neurons.\n",
    "\n",
    "Ns = number of samples in training data set.\n",
    "\n",
    "α = an arbitrary scaling factor usually 2-10."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 4\n",
    "A deep neural network (DNN) with three hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the hidden layers\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7136 - accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.6488 - accuracy: 0.6446\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.5958 - accuracy: 0.7562\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.5465 - accuracy: 0.7893\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.4987 - accuracy: 0.8140\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.8347\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.4167 - accuracy: 0.8347\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.3862 - accuracy: 0.8471\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.3599 - accuracy: 0.8512\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.8512\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.3265 - accuracy: 0.8554\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 931us/step - loss: 0.3151 - accuracy: 0.8636\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 989us/step - loss: 0.3037 - accuracy: 0.8760\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2933 - accuracy: 0.8843\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 994us/step - loss: 0.2843 - accuracy: 0.8884\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.2756 - accuracy: 0.8884\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2672 - accuracy: 0.8884\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.2591 - accuracy: 0.8926\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.2524 - accuracy: 0.8926\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2444 - accuracy: 0.8967\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2386 - accuracy: 0.8967\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 994us/step - loss: 0.2298 - accuracy: 0.9008\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2241 - accuracy: 0.9091\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2162 - accuracy: 0.9174\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 939us/step - loss: 0.2099 - accuracy: 0.9174\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 971us/step - loss: 0.2035 - accuracy: 0.9256\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 983us/step - loss: 0.1969 - accuracy: 0.9298\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.9463\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.9463\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 996us/step - loss: 0.1770 - accuracy: 0.9463\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1712 - accuracy: 0.9463\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 994us/step - loss: 0.1654 - accuracy: 0.9504\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 995us/step - loss: 0.1596 - accuracy: 0.9628\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1531 - accuracy: 0.9628\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.1475 - accuracy: 0.9669\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.9669\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1368 - accuracy: 0.9669\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1309 - accuracy: 0.9669\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9669\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1221 - accuracy: 0.9669\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1162 - accuracy: 0.9711\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.1127 - accuracy: 0.9711\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1094 - accuracy: 0.9752\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9752\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1005 - accuracy: 0.9752\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0970 - accuracy: 0.9793\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 852us/step - loss: 0.0934 - accuracy: 0.9793\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 963us/step - loss: 0.0899 - accuracy: 0.9793\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 994us/step - loss: 0.0871 - accuracy: 0.9793\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 998us/step - loss: 0.0831 - accuracy: 0.9793\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0804 - accuracy: 0.9835\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0777 - accuracy: 0.9835\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0745 - accuracy: 0.9835\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0719 - accuracy: 0.9876\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.0689 - accuracy: 0.9876\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 946us/step - loss: 0.0663 - accuracy: 0.9876\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.0640 - accuracy: 0.9876\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 985us/step - loss: 0.0627 - accuracy: 0.9876\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0591 - accuracy: 0.9876\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9876\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 945us/step - loss: 0.0557 - accuracy: 0.9876\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 942us/step - loss: 0.0541 - accuracy: 0.9876\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9876\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 976us/step - loss: 0.0500 - accuracy: 0.9876\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0483 - accuracy: 0.9876\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 998us/step - loss: 0.0457 - accuracy: 0.9876\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 952us/step - loss: 0.0445 - accuracy: 0.9876\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0423 - accuracy: 0.9876\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 869us/step - loss: 0.0412 - accuracy: 0.9876\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0390 - accuracy: 0.9876\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 0.9917\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0356 - accuracy: 0.9917\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0348 - accuracy: 0.9917\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 891us/step - loss: 0.0321 - accuracy: 0.9917\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9917\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.9917\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 974us/step - loss: 0.0277 - accuracy: 0.9917\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9917\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 898us/step - loss: 0.0253 - accuracy: 0.9959\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 994us/step - loss: 0.0242 - accuracy: 0.9959\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.9959\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 0.9959\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9959\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 911us/step - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 855us/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 994us/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 858us/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 987us/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 998us/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23c183ebc70>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0592 - accuracy: 0.7869\n",
      "Loss: 1.0591744184494019\n",
      "Accuracy: 0.7868852615356445\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 5\n",
    "A recurrent neural network (RNN) with two LSTM layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the LSTM layers\n",
    "model.add(LSTM(units=32, input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "model.add(LSTM(units=32))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 7ms/step - loss: 0.6852 - accuracy: 0.5950\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6757 - accuracy: 0.5909\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6690 - accuracy: 0.5744\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6614 - accuracy: 0.5702\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6572 - accuracy: 0.5868\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6507 - accuracy: 0.6074\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6429 - accuracy: 0.6281\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6340 - accuracy: 0.6446\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6242 - accuracy: 0.6860\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6103 - accuracy: 0.6901\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5942 - accuracy: 0.7025\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5709 - accuracy: 0.7397\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5495 - accuracy: 0.7355\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5282 - accuracy: 0.7397\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5206 - accuracy: 0.7645\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5221 - accuracy: 0.7521\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5206 - accuracy: 0.7438\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5247 - accuracy: 0.7314\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5105 - accuracy: 0.7479\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5056 - accuracy: 0.7645\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7727\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7686\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.7686\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4866 - accuracy: 0.7603\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4847 - accuracy: 0.7645\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7645\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7645\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7603\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7645\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.7934\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7934\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7851\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7934\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7851\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.8017\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7975\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7975\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.8017\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.8058\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.8058\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8017\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8099\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8017\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8223\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8099\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8058\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8017\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8306\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8182\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8306\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8264\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8512\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8264\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3852 - accuracy: 0.8182\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3812 - accuracy: 0.8182\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8264\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3807 - accuracy: 0.8306\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8099\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3719 - accuracy: 0.8554\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8388\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8306\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3662 - accuracy: 0.8306\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3629 - accuracy: 0.8306\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3587 - accuracy: 0.8430\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3590 - accuracy: 0.8430\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3578 - accuracy: 0.8347\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3551 - accuracy: 0.8512\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8512\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.8430\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3432 - accuracy: 0.8595\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3517 - accuracy: 0.8430\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3484 - accuracy: 0.8388\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3381 - accuracy: 0.8636\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8595\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8471\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8554\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8636\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3235 - accuracy: 0.8678\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3257 - accuracy: 0.8636\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.8678\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3221 - accuracy: 0.8636\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3224 - accuracy: 0.8512\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3114 - accuracy: 0.8636\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3116 - accuracy: 0.8760\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3128 - accuracy: 0.8678\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3093 - accuracy: 0.8802\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3069 - accuracy: 0.8802\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3100 - accuracy: 0.8678\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2987 - accuracy: 0.8760\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3005 - accuracy: 0.8636\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3022 - accuracy: 0.8802\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3089 - accuracy: 0.8678\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3120 - accuracy: 0.8678\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3073 - accuracy: 0.8760\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2959 - accuracy: 0.8636\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2873 - accuracy: 0.8636\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2824 - accuracy: 0.8802\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2801 - accuracy: 0.8719\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2729 - accuracy: 0.8719\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2729 - accuracy: 0.8760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23c19544430>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 3ms/step - loss: 0.8930 - accuracy: 0.6557\n",
      "Loss: 0.8929719924926758\n",
      "Accuracy: 0.6557376980781555\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Modelo 6\n",
    "A hybrid neural network with one convolutional layer, one LSTM layer, and one dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the convolutional layer\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "\n",
    "# Add the LSTM layer\n",
    "model.add(LSTM(units=32))\n",
    "\n",
    "# Add the dense layer\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 4ms/step - loss: 0.6847 - accuracy: 0.5496\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6710 - accuracy: 0.6529\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6612\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6440 - accuracy: 0.6612\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6287 - accuracy: 0.7149\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6121 - accuracy: 0.7190\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5905 - accuracy: 0.7149\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5649 - accuracy: 0.7355\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.7438\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5123 - accuracy: 0.7645\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.7893\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7851\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7769\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7851\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.8099\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.8058\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8099\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8099\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8264\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.8140\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.8347\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3803 - accuracy: 0.8182\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8306\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8388\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3699 - accuracy: 0.8388\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3692 - accuracy: 0.8471\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3634 - accuracy: 0.8471\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3662 - accuracy: 0.8388\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3572 - accuracy: 0.8636\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3580 - accuracy: 0.8471\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3592 - accuracy: 0.8554\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3613 - accuracy: 0.8430\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8512\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8471\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8595\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8554\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8512\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.8554\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8554\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3346 - accuracy: 0.8636\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3392 - accuracy: 0.8595\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8678\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8595\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.8636\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.8636\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3205 - accuracy: 0.8719\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3193 - accuracy: 0.8678\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.8719\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8760\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.8760\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8760\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3134 - accuracy: 0.8678\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3069 - accuracy: 0.8802\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3052 - accuracy: 0.8843\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2998 - accuracy: 0.8802\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2968 - accuracy: 0.8760\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3024 - accuracy: 0.8926\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.8802\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.8967\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2868 - accuracy: 0.8884\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2890 - accuracy: 0.9091\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3010 - accuracy: 0.8884\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3038 - accuracy: 0.8843\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.8719\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8802\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2820 - accuracy: 0.8843\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2708 - accuracy: 0.8926\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2745 - accuracy: 0.9091\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.9008\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2806 - accuracy: 0.8802\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2639 - accuracy: 0.9091\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.9008\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2572 - accuracy: 0.8884\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2560 - accuracy: 0.9132\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2581 - accuracy: 0.9008\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2647 - accuracy: 0.8884\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.9091\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.9091\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.8967\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2604 - accuracy: 0.9132\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2481 - accuracy: 0.9091\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2335 - accuracy: 0.9174\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2312 - accuracy: 0.9215\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2383 - accuracy: 0.9256\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2322 - accuracy: 0.9132\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2362 - accuracy: 0.9174\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2271 - accuracy: 0.9132\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2189 - accuracy: 0.9256\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2141 - accuracy: 0.9256\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2145 - accuracy: 0.9380\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9339\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9421\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9339\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2014 - accuracy: 0.9463\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2000 - accuracy: 0.9421\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1975 - accuracy: 0.9463\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1943 - accuracy: 0.9504\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1895 - accuracy: 0.9380\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1892 - accuracy: 0.9463\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1854 - accuracy: 0.9504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23c1ea3a170>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.7869\n",
      "Loss: 0.6587808132171631\n",
      "Accuracy: 0.7868852615356445\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f88dcba8d6815c5855e6c9ee3a17b25f591aa877fe6d8a099a93603a93c5cd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
