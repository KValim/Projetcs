{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Neste notebook, voc√™ codificar√° do zero seu terceiro agente de Reinforcement Learning jogando Montain Car usando Q-Learning"
      ],
      "metadata": {
        "id": "clnLGkknvrG_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRU_vXBrl1Jx"
      },
      "source": [
        "<img src=\"https://www.gymlibrary.dev/_images/mountain_car.gif\" alt=\"Environments\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üéÆ Environments:\n",
        "\n",
        ">\n",
        "\n",
        "- [Mountain Car](https://www.gymlibrary.dev/environments/classic_control/mountain_car/)\n",
        "\n",
        "\n",
        "###üìö RL-Library:\n",
        "\n",
        "- Python and NumPy\n",
        "- [Gym](https://www.gymlibrary.dev/)"
      ],
      "metadata": {
        "id": "DPTBOv9HYLZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalar depend√™ncias e criar um display virtual üîΩ\n"
      ],
      "metadata": {
        "id": "4gpxC1_kqUYe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XaULfDZDvrC"
      },
      "outputs": [],
      "source": [
        "!pip install gym==0.24\n",
        "!pip install pygame\n",
        "!pip install numpy\n",
        "\n",
        "!pip install huggingface_hub\n",
        "!pip install pickle5\n",
        "!pip install pyyaml==6.0\n",
        "!pip install imageio\n",
        "!pip install imageio_ffmpeg\n",
        "!pip install pyglet==1.5.1\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!apt update\n",
        "!apt install ffmpeg xvfb\n",
        "!pip install xvfbwrapper\n",
        "!pip install pyvirtualdisplay"
      ],
      "metadata": {
        "id": "n71uTX7qqzz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para garantir que as novas bibliotecas instaladas sejam usadas, **√†s vezes √© necess√°rio reiniciar o tempo de execu√ß√£o do notebook**. A pr√≥xima c√©lula for√ßar√° o **tempo de execu√ß√£o a travar, ent√£o voc√™ precisar√° se conectar novamente e executar o c√≥digo a partir daqui**."
      ],
      "metadata": {
        "id": "K6XC13pTfFiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "#os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "3kuZbWAkfHdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-7f-Swax_9x"
      },
      "source": [
        "## Importa√ß√£o de pacotes üì¶\n",
        "\n",
        "Al√©m das bibliotecas instaladas, utilizamos tamb√©m:\n",
        "\n",
        "- `random`: Para gerar n√∫meros aleat√≥rios (que ser√£o √∫teis para a pol√≠tica epsilon-greedy).\n",
        "- `imageio`: Para gerar um v√≠deo de replay."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "from collections import deque\n",
        "import time\n",
        "import random\n",
        "\n",
        "from IPython import display\n",
        "from IPython.display import HTML\n",
        "import pygame\n",
        "from base64 import b64encode\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "from time import sleep\n",
        "import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "import os"
      ],
      "metadata": {
        "id": "C3gl9kyS0SiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "metadata": {
        "id": "toaDg2Yfs_jA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 5\n",
        "tf.random.set_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "GNd3xcUftRqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNxUbPMP0akP"
      },
      "outputs": [],
      "source": [
        "env = gym.make('MountainCar-v0')\n",
        "env.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Action Space: {}\".format(env.action_space))\n",
        "print(\"State space: {}\".format(env.observation_space))"
      ],
      "metadata": {
        "id": "t7o3X7d-059g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXbTfdeJ1Xi9"
      },
      "source": [
        "### Verifique o Environment:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
        "print(\"Observation Space\", env.observation_space)\n",
        "print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"
      ],
      "metadata": {
        "id": "I5zArh3xvL4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
        "print(\"Action Space Shape\", env.action_space.n)\n",
        "print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"
      ],
      "metadata": {
        "id": "6Ys8w0e-vgU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_space = env.observation_space\n",
        "print(\"There are \", state_space, \" possible states\")\n",
        "\n",
        "action_space = env.action_space.n\n",
        "print(\"There are \", action_space, \" possible actions\")"
      ],
      "metadata": {
        "id": "U9TZWTm1v5MV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estudando melhor o espa√ßo de Observa√ß√£o temos a seguinte descri√ß√£o do Enviroment:\n",
        "\n",
        "Given an action, the mountain car follows the following transition dynamics:\n",
        "\n",
        "velocityt+1 = velocityt + (action - 1) * force - cos(3 * positiont) * gravity\n",
        "\n",
        "positiont+1 = positiont + velocityt+1\n",
        "\n",
        "where force = 0.001 and gravity = 0.0025. The collisions at either end are inelastic with the velocity set to 0 upon collision with the wall. The position is clipped to the range [-1.2, 0.6] and velocity is clipped to the range [-0.07, 0.07].\n"
      ],
      "metadata": {
        "id": "8lJigamlakTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_v = env.observation_space.low\n",
        "print(\"Min possible values \", min_v)"
      ],
      "metadata": {
        "id": "CDjti_WYcIOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_v = env.observation_space.high\n",
        "print(\"Max possible values \", max_v)"
      ],
      "metadata": {
        "id": "E5dTya-ucujs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = env.reset()"
      ],
      "metadata": {
        "id": "V-rVzBZu0Tih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.step(env.action_space.sample())\n",
        "img = env.render(mode='rgb_array')"
      ],
      "metadata": {
        "id": "HS_q2svv0giq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "2X6_u4bN0oDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##O Grande desafio deste notebook √© pensar em uma forma de discretizar a velocidade e a posi√ß√£o do carrinho em estados para criar a nossa Q-Table\n"
      ],
      "metadata": {
        "id": "EQHcLLXCdBFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processo de Valida√ß√£o"
      ],
      "metadata": {
        "id": "olKX3dSK1Put"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from IPython.core.display import display, HTML\n",
        "from base64 import b64encode\n",
        "import imageio\n",
        "\n",
        "# Configura√ß√µes e constantes\n",
        "LEARNING_RATE = 0.1\n",
        "DISCOUNT = 0.95\n",
        "EPISODES = 5000\n",
        "SHOW_EVERY = 500\n",
        "STATS_EVERY = 1\n",
        "\n",
        "# Vari√°veis para a decaimento do epsilon\n",
        "epsilon = 1\n",
        "START_EPSILON_DECAYING = 1\n",
        "END_EPSILON_DECAYING = EPISODES // 2\n",
        "epsilon_decay_value = epsilon / (END_EPSILON_DECAYING - START_EPSILON_DECAYING)\n",
        "\n",
        "# Inicializa√ß√£o do ambiente\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "env.reset()\n",
        "\n",
        "# Inicializa√ß√£o da tabela Q\n",
        "DISCRETE_OS_SIZE = [20, 20]\n",
        "discrete_os_win_size = (env.observation_space.high - env.observation_space.low) / DISCRETE_OS_SIZE\n",
        "q_table = np.random.uniform(low=-2, high=0, size=(DISCRETE_OS_SIZE + [env.action_space.n]))\n",
        "\n",
        "# Vari√°veis para estat√≠sticas\n",
        "ep_rewards = []\n",
        "aggr_ep_rewards = {'ep': [], 'avg': [], 'min': [], 'max': []}\n",
        "\n",
        "# Vari√°vel para armazenar imagens\n",
        "images = []\n",
        "\n",
        "def get_discrete_state(state):\n",
        "    \"\"\"Transforma estados cont√≠nuos em estados discretos\"\"\"\n",
        "    discrete_state = (state - env.observation_space.low) / discrete_os_win_size\n",
        "    return tuple(discrete_state.astype(np.int))\n",
        "\n",
        "def play_episode(images, video_path):\n",
        "    kargs = {'macro_block_size': 1}\n",
        "    imageio.mimsave(video_path, [np.array(img) for i, img in enumerate(images)], fps=15, **kargs)\n",
        "\n",
        "for episode in range(EPISODES):\n",
        "    episode_reward = 0\n",
        "    discrete_state = get_discrete_state(env.reset())\n",
        "    done = False\n",
        "\n",
        "    if episode % SHOW_EVERY == 0:\n",
        "        render = True\n",
        "        print(f\"Episode: {episode}\")\n",
        "    else:\n",
        "        render = False\n",
        "\n",
        "    while not done:\n",
        "        if render:\n",
        "            images.append(env.render(mode='rgb_array'))\n",
        "\n",
        "        if np.random.random() > epsilon:\n",
        "            action = np.argmax(q_table[discrete_state])\n",
        "        else:\n",
        "            action = np.random.randint(0, env.action_space.n)\n",
        "\n",
        "        new_state, reward, done, _ = env.step(action)\n",
        "        episode_reward += reward\n",
        "\n",
        "        new_discrete_state = get_discrete_state(new_state)\n",
        "\n",
        "        if not done:\n",
        "            max_future_q = np.max(q_table[new_discrete_state])\n",
        "            current_q = q_table[discrete_state + (action, )]\n",
        "            new_q = (1 - LEARNING_RATE) * current_q + LEARNING_RATE * (reward + DISCOUNT * max_future_q)\n",
        "            q_table[discrete_state + (action, )] = new_q\n",
        "\n",
        "        elif new_state[0] >= env.goal_position:\n",
        "            q_table[discrete_state + (action, )] = 0\n",
        "\n",
        "        discrete_state = new_discrete_state\n",
        "\n",
        "    if render:\n",
        "        video_path = \"replay.mp4\"\n",
        "        play_episode(images, video_path)\n",
        "        mp4 = open(video_path,'rb').read()\n",
        "        data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "        display(HTML(f\"\"\"\n",
        "        <video width=400 controls>\n",
        "              <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "        </video>\n",
        "        \"\"\"))\n",
        "        images = []\n",
        "\n",
        "    if END_EPSILON_DECAYING >= episode >= START_EPSILON_DECAYING:\n",
        "        epsilon -= epsilon_decay_value\n",
        "\n",
        "    ep_rewards.append(episode_reward)\n",
        "\n",
        "    if episode % STATS_EVERY == 0:\n",
        "        average_reward = sum(ep_rewards[-STATS_EVERY:])/STATS_EVERY\n",
        "        aggr_ep_rewards['ep'].append(episode)\n",
        "        aggr_ep_rewards['avg'].append(average_reward)\n",
        "        aggr_ep_rewards['min'].append(min(ep_rewards[-STATS_EVERY:]))\n",
        "        aggr_ep_rewards['max'].append(max(ep_rewards[-STATS_EVERY:]))\n",
        "        print(f\"Episode: {episode}, average: {average_reward}, min: {min(ep_rewards[-STATS_EVERY:])}, max: {max(ep_rewards[-STATS_EVERY:])}\")\n",
        "\n",
        "env.close()\n"
      ],
      "metadata": {
        "id": "8ik5iS7Y31s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"replay.mp4\"\n",
        "play_episode(images, video_path)\n",
        "mp4 = open(video_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "display(HTML(f\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\"))\n",
        "images = []"
      ],
      "metadata": {
        "id": "jNPsaWEQ7zQF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}