{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Neste notebook, vocÃª codificarÃ¡ do zero seu terceiro agente de Reinforcement Learning jogando Montain Car usando Q-Learning"
      ],
      "metadata": {
        "id": "clnLGkknvrG_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRU_vXBrl1Jx"
      },
      "source": [
        "<img src=\"https://www.gymlibrary.dev/_images/mountain_car.gif\" alt=\"Environments\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ðŸŽ® Environments:\n",
        "\n",
        ">\n",
        "\n",
        "- [Mountain Car](https://www.gymlibrary.dev/environments/classic_control/mountain_car/)\n",
        "\n",
        "\n",
        "###ðŸ“š RL-Library:\n",
        "\n",
        "- Python and NumPy\n",
        "- [Gym](https://www.gymlibrary.dev/)"
      ],
      "metadata": {
        "id": "DPTBOv9HYLZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalar dependÃªncias e criar um display virtual ðŸ”½\n"
      ],
      "metadata": {
        "id": "4gpxC1_kqUYe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XaULfDZDvrC"
      },
      "outputs": [],
      "source": [
        "!pip install gym==0.24\n",
        "!pip install pygame\n",
        "!pip install numpy\n",
        "\n",
        "!pip install huggingface_hub\n",
        "!pip install pickle5\n",
        "!pip install pyyaml==6.0\n",
        "!pip install imageio\n",
        "!pip install imageio_ffmpeg\n",
        "!pip install pyglet==1.5.1\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!apt update\n",
        "!apt install ffmpeg xvfb\n",
        "!pip install xvfbwrapper\n",
        "!pip install pyvirtualdisplay"
      ],
      "metadata": {
        "id": "n71uTX7qqzz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para garantir que as novas bibliotecas instaladas sejam usadas, **Ã s vezes Ã© necessÃ¡rio reiniciar o tempo de execuÃ§Ã£o do notebook**. A prÃ³xima cÃ©lula forÃ§arÃ¡ o **tempo de execuÃ§Ã£o a travar, entÃ£o vocÃª precisarÃ¡ se conectar novamente e executar o cÃ³digo a partir daqui**."
      ],
      "metadata": {
        "id": "K6XC13pTfFiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "#os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "3kuZbWAkfHdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-7f-Swax_9x"
      },
      "source": [
        "## ImportaÃ§Ã£o de pacotes ðŸ“¦\n",
        "\n",
        "AlÃ©m das bibliotecas instaladas, utilizamos tambÃ©m:\n",
        "\n",
        "- `random`: Para gerar nÃºmeros aleatÃ³rios (que serÃ£o Ãºteis para a polÃ­tica epsilon-greedy).\n",
        "- `imageio`: Para gerar um vÃ­deo de replay."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "from collections import deque\n",
        "import time\n",
        "import random\n",
        "\n",
        "from IPython import display\n",
        "from IPython.display import HTML\n",
        "import pygame\n",
        "from base64 import b64encode\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "from time import sleep\n",
        "import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "import os"
      ],
      "metadata": {
        "id": "C3gl9kyS0SiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "metadata": {
        "id": "toaDg2Yfs_jA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 5\n",
        "tf.random.set_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "GNd3xcUftRqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNxUbPMP0akP"
      },
      "outputs": [],
      "source": [
        "env = gym.make('MountainCar-v0')\n",
        "env.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Action Space: {}\".format(env.action_space))\n",
        "print(\"State space: {}\".format(env.observation_space))"
      ],
      "metadata": {
        "id": "t7o3X7d-059g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXbTfdeJ1Xi9"
      },
      "source": [
        "### Verifique o Environment:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
        "print(\"Observation Space\", env.observation_space)\n",
        "print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"
      ],
      "metadata": {
        "id": "I5zArh3xvL4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
        "print(\"Action Space Shape\", env.action_space.n)\n",
        "print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"
      ],
      "metadata": {
        "id": "6Ys8w0e-vgU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_space = env.observation_space\n",
        "print(\"There are \", state_space, \" possible states\")\n",
        "\n",
        "action_space = env.action_space.n\n",
        "print(\"There are \", action_space, \" possible actions\")"
      ],
      "metadata": {
        "id": "U9TZWTm1v5MV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estudando melhor o espaÃ§o de ObservaÃ§Ã£o temos a seguinte descriÃ§Ã£o do Enviroment:\n",
        "\n",
        "Given an action, the mountain car follows the following transition dynamics:\n",
        "\n",
        "velocityt+1 = velocityt + (action - 1) * force - cos(3 * positiont) * gravity\n",
        "\n",
        "positiont+1 = positiont + velocityt+1\n",
        "\n",
        "where force = 0.001 and gravity = 0.0025. The collisions at either end are inelastic with the velocity set to 0 upon collision with the wall. The position is clipped to the range [-1.2, 0.6] and velocity is clipped to the range [-0.07, 0.07].\n"
      ],
      "metadata": {
        "id": "8lJigamlakTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_v = env.observation_space.low\n",
        "print(\"Min possible values \", min_v)"
      ],
      "metadata": {
        "id": "CDjti_WYcIOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_v = env.observation_space.high\n",
        "print(\"Max possible values \", max_v)"
      ],
      "metadata": {
        "id": "E5dTya-ucujs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = env.reset()"
      ],
      "metadata": {
        "id": "V-rVzBZu0Tih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.step(env.action_space.sample())\n",
        "img = env.render(mode='rgb_array')"
      ],
      "metadata": {
        "id": "HS_q2svv0giq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "2X6_u4bN0oDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##O Grande desafio deste notebook Ã© pensar em uma forma de discretizar a velocidade e a posiÃ§Ã£o do carrinho em estados para criar a nossa Q-Table\n"
      ],
      "metadata": {
        "id": "EQHcLLXCdBFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processo de ValidaÃ§Ã£o"
      ],
      "metadata": {
        "id": "olKX3dSK1Put"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from IPython.core.display import display, HTML\n",
        "from base64 import b64encode\n",
        "import imageio\n",
        "\n",
        "# ConfiguraÃ§Ãµes e constantes\n",
        "LEARNING_RATE = 0.1\n",
        "DISCOUNT = 0.95\n",
        "EPISODES = 5000\n",
        "SHOW_EVERY = 500\n",
        "STATS_EVERY = 1\n",
        "\n",
        "# VariÃ¡veis para a decaimento do epsilon\n",
        "epsilon = 1\n",
        "START_EPSILON_DECAYING = 1\n",
        "END_EPSILON_DECAYING = EPISODES // 2\n",
        "epsilon_decay_value = epsilon / (END_EPSILON_DECAYING - START_EPSILON_DECAYING)\n",
        "\n",
        "# InicializaÃ§Ã£o do ambiente\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "env.reset()\n",
        "\n",
        "# InicializaÃ§Ã£o da tabela Q\n",
        "DISCRETE_OS_SIZE = [20, 20]\n",
        "discrete_os_win_size = (env.observation_space.high - env.observation_space.low) / DISCRETE_OS_SIZE\n",
        "q_table = np.random.uniform(low=-2, high=0, size=(DISCRETE_OS_SIZE + [env.action_space.n]))\n",
        "\n",
        "# VariÃ¡veis para estatÃ­sticas\n",
        "ep_rewards = []\n",
        "aggr_ep_rewards = {'ep': [], 'avg': [], 'min': [], 'max': []}\n",
        "\n",
        "# VariÃ¡vel para armazenar imagens\n",
        "images = []\n",
        "\n",
        "def get_discrete_state(state):\n",
        "    \"\"\"Transforma estados contÃ­nuos em estados discretos\"\"\"\n",
        "    discrete_state = (state - env.observation_space.low) / discrete_os_win_size\n",
        "    return tuple(discrete_state.astype(np.int))\n",
        "\n",
        "def play_episode(images, video_path):\n",
        "    kargs = {'macro_block_size': 1}\n",
        "    imageio.mimsave(video_path, [np.array(img) for i, img in enumerate(images)], fps=15, **kargs)\n",
        "\n",
        "for episode in range(EPISODES):\n",
        "    episode_reward = 0\n",
        "    discrete_state = get_discrete_state(env.reset())\n",
        "    done = False\n",
        "\n",
        "    if episode % SHOW_EVERY == 0:\n",
        "        render = True\n",
        "        print(f\"Episode: {episode}\")\n",
        "    else:\n",
        "        render = False\n",
        "\n",
        "    while not done:\n",
        "        if render:\n",
        "            images.append(env.render(mode='rgb_array'))\n",
        "\n",
        "        if np.random.random() > epsilon:\n",
        "            action = np.argmax(q_table[discrete_state])\n",
        "        else:\n",
        "            action = np.random.randint(0, env.action_space.n)\n",
        "\n",
        "        new_state, reward, done, _ = env.step(action)\n",
        "        episode_reward += reward\n",
        "\n",
        "        new_discrete_state = get_discrete_state(new_state)\n",
        "\n",
        "        if not done:\n",
        "            max_future_q = np.max(q_table[new_discrete_state])\n",
        "            current_q = q_table[discrete_state + (action, )]\n",
        "            new_q = (1 - LEARNING_RATE) * current_q + LEARNING_RATE * (reward + DISCOUNT * max_future_q)\n",
        "            q_table[discrete_state + (action, )] = new_q\n",
        "\n",
        "        elif new_state[0] >= env.goal_position:\n",
        "            q_table[discrete_state + (action, )] = 0\n",
        "\n",
        "        discrete_state = new_discrete_state\n",
        "\n",
        "    if render:\n",
        "        video_path = \"replay.mp4\"\n",
        "        play_episode(images, video_path)\n",
        "        mp4 = open(video_path,'rb').read()\n",
        "        data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "        display(HTML(f\"\"\"\n",
        "        <video width=400 controls>\n",
        "              <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "        </video>\n",
        "        \"\"\"))\n",
        "        images = []\n",
        "\n",
        "    if END_EPSILON_DECAYING >= episode >= START_EPSILON_DECAYING:\n",
        "        epsilon -= epsilon_decay_value\n",
        "\n",
        "    ep_rewards.append(episode_reward)\n",
        "\n",
        "    if episode % STATS_EVERY == 0:\n",
        "        average_reward = sum(ep_rewards[-STATS_EVERY:])/STATS_EVERY\n",
        "        aggr_ep_rewards['ep'].append(episode)\n",
        "        aggr_ep_rewards['avg'].append(average_reward)\n",
        "        aggr_ep_rewards['min'].append(min(ep_rewards[-STATS_EVERY:]))\n",
        "        aggr_ep_rewards['max'].append(max(ep_rewards[-STATS_EVERY:]))\n",
        "        print(f\"Episode: {episode}, average: {average_reward}, min: {min(ep_rewards[-STATS_EVERY:])}, max: {max(ep_rewards[-STATS_EVERY:])}\")\n",
        "\n",
        "env.close()\n"
      ],
      "metadata": {
        "id": "8ik5iS7Y31s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"replay.mp4\"\n",
        "play_episode(images, video_path)\n",
        "mp4 = open(video_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "display(HTML(f\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\"))\n",
        "images = []"
      ],
      "metadata": {
        "id": "jNPsaWEQ7zQF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}