{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VDbi6PDS9MYO"
      },
      "source": [
        "***Participantes (RM - NOME):***<br>\n",
        "\n",
        "346269 - KAIQUE VALIM<br>\n",
        "346320 - VITOR VENARDOS<br>\n",
        "346364 - ATONIO JUNIOR<br>\n",
        "346851 - GUSTAVO SECCO<br>\n",
        "346922 - RENAN COVRRE<br>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7xw6WhaNo4k3"
      },
      "source": [
        "# **Criar um classificador de chamados aplicando técnicas de PLN**\n",
        "---\n",
        "\n",
        "A **QuantumFinance** tem um canal de atendimento via chat e precisar classificar os assuntos dos atendimentos para melhorar as tratativas dos chamados dos clientes. O canal recebe textos abertos dos clientes relatando o problema e/ou dúvida e depois é direcionado para algum uma área especialista no assunto para uma melhor tratativa.​\n",
        "\n",
        "Crie um modelo classificador de assuntos aplicando técnicas de PLN, que consiga classificar através de um texto o assunto conforme disponível na base de dados [1] para treinamento e validação do modelo seu modelo.​\n",
        "\n",
        "O modelo precisar atingir um score na **métrica F1 Score superior a 75%**. Utilize o dataset [1] para treinar e testar o modelo, separe o dataset em duas amostras (75% para treinamento e 25% para teste com o randon_state igual a 42).​\n",
        "\n",
        "Fique à vontade para testar e explorar as técnicas de pré-processamento, abordagens de NLP, algoritmos e bibliotecas, mas explique e justifique as suas decisões durante o desenvolvimento.​\n",
        "\n",
        "**Composição da nota:​**\n",
        "\n",
        "**50%** - Demonstrações das aplicações das técnicas de PLN (regras, pré-processamentos, tratamentos, variedade de modelos aplicados, organização do pipeline, etc.)​\n",
        "\n",
        "**50%** - Baseado na performance (score) obtida com a amostra de teste no pipeline do modelo campeão (validar com  a Métrica F1 Score). **Separar o pipeline completo do modelo campeão conforme template.​**\n",
        "\n",
        "O trabalho poderá ser feito em grupo de até 4 pessoas (mesmo grupo do Startup One).\n",
        "\n",
        "**[1] = ​https://dados-ml-pln.s3.sa-east-1.amazonaws.com/tickets_reclamacoes_classificados.csv**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports do sistema operacional (OS)\n",
        "import os\n",
        "\n",
        "# Imports do pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Imports relacionados a expressões regulares\n",
        "import re\n",
        "\n",
        "# Imports relacionados ao processamento de linguagem natural (NLP)\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Imports relacionados ao machine learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DMBI8SQtps1n"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_reclamacao</th>\n",
              "      <th>data_abertura</th>\n",
              "      <th>categoria</th>\n",
              "      <th>descricao_reclamacao</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3229299</td>\n",
              "      <td>2019-05-01T12:00:00-05:00</td>\n",
              "      <td>Hipotecas / Empréstimos</td>\n",
              "      <td>Bom dia, meu nome é xxxx xxxx e agradeço se vo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3199379</td>\n",
              "      <td>2019-04-02T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>Atualizei meu cartão xxxx xxxx em xx/xx/2018 e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3233499</td>\n",
              "      <td>2019-05-06T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>O cartão Chase foi relatado em xx/xx/2019. No ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3180294</td>\n",
              "      <td>2019-03-14T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>Em xx/xx/2018, enquanto tentava reservar um ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3224980</td>\n",
              "      <td>2019-04-27T12:00:00-05:00</td>\n",
              "      <td>Serviços de conta bancária</td>\n",
              "      <td>Meu neto me dê cheque por {$ 1600,00} Eu depos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21067</th>\n",
              "      <td>3094545</td>\n",
              "      <td>2018-12-07T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>Depois de ser um cliente de cartão de persegui...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21068</th>\n",
              "      <td>3091984</td>\n",
              "      <td>2018-12-05T12:00:00-05:00</td>\n",
              "      <td>Roubo / Relatório de disputa</td>\n",
              "      <td>Na quarta -feira, xx/xx/xxxx, liguei para o Ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21069</th>\n",
              "      <td>3133355</td>\n",
              "      <td>2019-01-25T12:00:00-05:00</td>\n",
              "      <td>Roubo / Relatório de disputa</td>\n",
              "      <td>Não estou familiarizado com o XXXX Pay e não e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21070</th>\n",
              "      <td>3110963</td>\n",
              "      <td>2018-12-27T12:00:00-05:00</td>\n",
              "      <td>Outros</td>\n",
              "      <td>Eu tive crédito impecável por 30 anos. Eu tive...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21071</th>\n",
              "      <td>2001189</td>\n",
              "      <td>2016-07-06T12:00:00-05:00</td>\n",
              "      <td>Outros</td>\n",
              "      <td>Mais de 10 anos atrás, encerrei minhas contas ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21072 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       id_reclamacao              data_abertura  \\\n",
              "0            3229299  2019-05-01T12:00:00-05:00   \n",
              "1            3199379  2019-04-02T12:00:00-05:00   \n",
              "2            3233499  2019-05-06T12:00:00-05:00   \n",
              "3            3180294  2019-03-14T12:00:00-05:00   \n",
              "4            3224980  2019-04-27T12:00:00-05:00   \n",
              "...              ...                        ...   \n",
              "21067        3094545  2018-12-07T12:00:00-05:00   \n",
              "21068        3091984  2018-12-05T12:00:00-05:00   \n",
              "21069        3133355  2019-01-25T12:00:00-05:00   \n",
              "21070        3110963  2018-12-27T12:00:00-05:00   \n",
              "21071        2001189  2016-07-06T12:00:00-05:00   \n",
              "\n",
              "                                 categoria  \\\n",
              "0                  Hipotecas / Empréstimos   \n",
              "1      Cartão de crédito / Cartão pré-pago   \n",
              "2      Cartão de crédito / Cartão pré-pago   \n",
              "3      Cartão de crédito / Cartão pré-pago   \n",
              "4               Serviços de conta bancária   \n",
              "...                                    ...   \n",
              "21067  Cartão de crédito / Cartão pré-pago   \n",
              "21068         Roubo / Relatório de disputa   \n",
              "21069         Roubo / Relatório de disputa   \n",
              "21070                               Outros   \n",
              "21071                               Outros   \n",
              "\n",
              "                                    descricao_reclamacao  \n",
              "0      Bom dia, meu nome é xxxx xxxx e agradeço se vo...  \n",
              "1      Atualizei meu cartão xxxx xxxx em xx/xx/2018 e...  \n",
              "2      O cartão Chase foi relatado em xx/xx/2019. No ...  \n",
              "3      Em xx/xx/2018, enquanto tentava reservar um ti...  \n",
              "4      Meu neto me dê cheque por {$ 1600,00} Eu depos...  \n",
              "...                                                  ...  \n",
              "21067  Depois de ser um cliente de cartão de persegui...  \n",
              "21068  Na quarta -feira, xx/xx/xxxx, liguei para o Ch...  \n",
              "21069  Não estou familiarizado com o XXXX Pay e não e...  \n",
              "21070  Eu tive crédito impecável por 30 anos. Eu tive...  \n",
              "21071  Mais de 10 anos atrás, encerrei minhas contas ...  \n",
              "\n",
              "[21072 rows x 4 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('https://dados-ml-pln.s3.sa-east-1.amazonaws.com/tickets_reclamacoes_classificados.csv', delimiter=';')\n",
        "df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s__lBzDQwrcG",
        "outputId": "9c4faa96-70b9-4255-f130-9f12e0548ab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21072 entries, 0 to 21071\n",
            "Data columns (total 4 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   id_reclamacao         21072 non-null  int64 \n",
            " 1   data_abertura         21072 non-null  object\n",
            " 2   categoria             21072 non-null  object\n",
            " 3   descricao_reclamacao  21072 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 658.6+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nze8UbKhosm9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Serviços de conta bancária             5161\n",
              " Cartão de crédito / Cartão pré-pago    5006\n",
              " Roubo / Relatório de disputa           4822\n",
              " Hipotecas / Empréstimos                3850\n",
              " Outros                                 2233\n",
              " Name: categoria, dtype: int64,\n",
              " id_reclamacao           0\n",
              " data_abertura           0\n",
              " categoria               0\n",
              " descricao_reclamacao    0\n",
              " dtype: int64,\n",
              " 247.7824126803341)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verificar a distribuição das categorias\n",
        "category_counts = df['categoria'].value_counts()\n",
        "\n",
        "# Verificar valores ausentes\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Calcular a contagem média de palavras na descrição\n",
        "df['word_count'] = df['descricao_reclamacao'].apply(lambda x: len(str(x).split()))\n",
        "average_word_count = df['word_count'].mean()\n",
        "\n",
        "category_counts, missing_values, average_word_count\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stopwords e Lemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ue0nV0uVo3OZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\nltk_data\n",
            "[nltk_data]     ...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\nltk_data\n",
            "[nltk_data]     ...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_reclamacao</th>\n",
              "      <th>data_abertura</th>\n",
              "      <th>categoria</th>\n",
              "      <th>descricao_reclamacao</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3229299</td>\n",
              "      <td>2019-05-01T12:00:00-05:00</td>\n",
              "      <td>Hipotecas / Empréstimos</td>\n",
              "      <td>bom dia nome xxxx xxxx agrade voc puder ajudar...</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3199379</td>\n",
              "      <td>2019-04-02T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>atualizei cart xxxx xxxx xx xx informado agent...</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3233499</td>\n",
              "      <td>2019-05-06T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>cart chase relatado xx xx entanto pedido fraud...</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3180294</td>\n",
              "      <td>2019-03-14T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>xx xx enquanto tentava reservar ticket xxxx xx...</td>\n",
              "      <td>276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3224980</td>\n",
              "      <td>2019-04-27T12:00:00-05:00</td>\n",
              "      <td>Serviços de conta bancária</td>\n",
              "      <td>neto d cheque depositei conta chase fundo limp...</td>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id_reclamacao              data_abertura  \\\n",
              "0        3229299  2019-05-01T12:00:00-05:00   \n",
              "1        3199379  2019-04-02T12:00:00-05:00   \n",
              "2        3233499  2019-05-06T12:00:00-05:00   \n",
              "3        3180294  2019-03-14T12:00:00-05:00   \n",
              "4        3224980  2019-04-27T12:00:00-05:00   \n",
              "\n",
              "                             categoria  \\\n",
              "0              Hipotecas / Empréstimos   \n",
              "1  Cartão de crédito / Cartão pré-pago   \n",
              "2  Cartão de crédito / Cartão pré-pago   \n",
              "3  Cartão de crédito / Cartão pré-pago   \n",
              "4           Serviços de conta bancária   \n",
              "\n",
              "                                descricao_reclamacao  word_count  \n",
              "0  bom dia nome xxxx xxxx agrade voc puder ajudar...          88  \n",
              "1  atualizei cart xxxx xxxx xx xx informado agent...          58  \n",
              "2  cart chase relatado xx xx entanto pedido fraud...          33  \n",
              "3  xx xx enquanto tentava reservar ticket xxxx xx...         276  \n",
              "4  neto d cheque depositei conta chase fundo limp...         108  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Baixar os dados necessários do NLTK\n",
        "nltk.download(['stopwords', 'wordnet'])\n",
        "\n",
        "# Inicializa o lematizador\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "# Define uma função para limpar o texto\n",
        "def clean_text(text):\n",
        "    # Remove pontuações e caracteres especiais (mantém apenas letras do alfabeto)\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    \n",
        "    # Converte para minúsculas\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Tokeniza e remove as palavras de parada\n",
        "    text = text.split()\n",
        "    text = [wnl.lemmatize(word) for word in text if not word in set(stopwords.words('portuguese'))]\n",
        "    \n",
        "    # Une as palavras de volta em uma única string\n",
        "    text = ' '.join(text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Limpa a coluna descrição\n",
        "df['descricao_reclamacao'] = df['descricao_reclamacao'].apply(clean_text)\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FziwgqJmw9OD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((15804,), (5268,), (15804,), (5268,))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializa o codificador de rótulos\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Codifica os rótulos (categorias)\n",
        "df['categoria'] = le.fit_transform(df['categoria'])\n",
        "\n",
        "# Divide os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['descricao_reclamacao'], df['categoria'], test_size=0.25, random_state=42)\n",
        "\n",
        "# Verifica as dimensões dos conjuntos resultantes\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "25cBRwGAw8-1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((15804, 32463), (5268, 32463))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializa o vetorizador TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Ajusta o vetorizador aos dados de treino e transforma os dados de treino\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transforma os dados de teste\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Verifica as dimensões das matrizes TF-IDF resultantes\n",
        "X_train_tfidf.shape, X_test_tfidf.shape\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializa SMOTE\n",
        "smote = SMOTE()\n",
        "\n",
        "# Adapta SMOTE aos dados de treino\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_tfidf, y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'C': 10}\n",
            "0.9284321214638609\n",
            "{'n_estimators': 300}\n",
            "0.8885586516849966\n"
          ]
        }
      ],
      "source": [
        "# Define os modelos\n",
        "log_reg = LogisticRegression()\n",
        "rand_forest = RandomForestClassifier()\n",
        "\n",
        "# Define os parâmetros a serem buscados\n",
        "log_reg_params = { 'C': [0.1, 1, 10] }\n",
        "rand_forest_params = { 'n_estimators': [100, 200, 300] }\n",
        "\n",
        "# Inicializa GridSearchCV para regressão logística\n",
        "grid_search_log_reg = GridSearchCV(estimator=log_reg, param_grid=log_reg_params, scoring='f1_weighted', cv=5)\n",
        "\n",
        "# Ajusta GridSearchCV aos dados de treinamento balanceados\n",
        "grid_search_log_reg.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Imprime os melhores parâmetros e a melhor pontuação para regressão logística\n",
        "print(grid_search_log_reg.best_params_)\n",
        "print(grid_search_log_reg.best_score_)\n",
        "\n",
        "# Inicializa GridSearchCV para floresta aleatória\n",
        "grid_search_rand_forest = GridSearchCV(estimator=rand_forest, param_grid=rand_forest_params, scoring='f1_weighted', cv=5)\n",
        "\n",
        "# Ajusta GridSearchCV aos dados de treinamento balanceados\n",
        "grid_search_rand_forest.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Imprime os melhores parâmetros e a melhor pontuação para floresta aleatória\n",
        "print(grid_search_rand_forest.best_params_)\n",
        "print(grid_search_rand_forest.best_score_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                     precision    recall  f1-score   support\n",
            "\n",
            "Cartão de crédito / Cartão pré-pago       0.92      0.91      0.92      1290\n",
            "            Hipotecas / Empréstimos       0.92      0.92      0.92       922\n",
            "                             Outros       0.87      0.90      0.89       549\n",
            "       Roubo / Relatório de disputa       0.89      0.88      0.89      1204\n",
            "         Serviços de conta bancária       0.92      0.92      0.92      1303\n",
            "\n",
            "                           accuracy                           0.91      5268\n",
            "                          macro avg       0.90      0.91      0.91      5268\n",
            "                       weighted avg       0.91      0.91      0.91      5268\n",
            "\n",
            "                                     precision    recall  f1-score   support\n",
            "\n",
            "Cartão de crédito / Cartão pré-pago       0.85      0.89      0.87      1290\n",
            "            Hipotecas / Empréstimos       0.89      0.89      0.89       922\n",
            "                             Outros       0.83      0.65      0.73       549\n",
            "       Roubo / Relatório de disputa       0.86      0.81      0.83      1204\n",
            "         Serviços de conta bancária       0.83      0.91      0.87      1303\n",
            "\n",
            "                           accuracy                           0.85      5268\n",
            "                          macro avg       0.85      0.83      0.84      5268\n",
            "                       weighted avg       0.85      0.85      0.85      5268\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Use o melhor modelo de regressão logística para fazer previsões no conjunto de teste\n",
        "best_log_reg = grid_search_log_reg.best_estimator_\n",
        "y_pred_log_reg = best_log_reg.predict(X_test_tfidf)\n",
        "\n",
        "# Gere e imprima o relatório de classificação para a regressão logística\n",
        "print(classification_report(y_test, y_pred_log_reg, target_names=le.classes_))\n",
        "\n",
        "# Use o melhor modelo de floresta aleatória para fazer previsões no conjunto de teste\n",
        "best_rand_forest = grid_search_rand_forest.best_estimator_\n",
        "y_pred_rand_forest = best_rand_forest.predict(X_test_tfidf)\n",
        "\n",
        "# Gere e imprima o relatório de classificação para a floresta aleatória\n",
        "print(classification_report(y_test, y_pred_rand_forest, target_names=le.classes_))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Melhor modelo: LogisticRegression(C=10)\n",
        "\n",
        "F1 weighted médio = 0.91"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
