{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "da761ac2-f680-579c-9085-fb3e706dbf2c",
        "openai_ephemeral_user_id": "7e6b40a0-fb08-5478-8012-7e0fb23a0c76",
        "openai_subdivision1_iso_code": "BR-SP"
      }
    },
    "noteable": {
      "last_transaction_id": "922724c1-14a9-4f44-aa7b-1784ed8726ca"
    },
    "selected_hardware_size": "small"
  },
  "cells": [
    {
      "id": "505d81a9-20df-4f07-9c83-9628a49d0c65",
      "cell_type": "markdown",
      "source": "# Autoencoder Simplificado para o Dataset Fashion MNIST\n\nNeste notebook, vamos construir um autoencoder simplificado para o dataset Fashion MNIST. O objetivo é aprender a representação compacta dos dados e, em seguida, usar essa representação para reconstruir os dados originais.\n\nO notebook está estruturado da seguinte maneira:\n\n1. Análise Exploratória de Dados (EDA)\n2. Construção e Treinamento do Autoencoder\n3. Visualização do Resultado do Decoder\n4. Construção e Comparação de Classificadores RandomForest e XgBoost\n5. Visualização de Dados com TSNE\n6. Repetição do Processo com um Autoencoder Convolucional\n7. Comparação dos Resultados (loss) do Autoencoder Simplificado e Convolucional\n8. Utilização da Última Camada de Max Pooling como Feature para um Classificador\n9. Visualização de Dados com TSNE",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "69178e27-b2bf-42b4-9dd9-938b35ece202",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Importando as bibliotecas necessárias\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.manifold import TSNE\nfrom xgboost import XGBClassifier\n\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.5)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntf.random.set_seed(RANDOM_SEED)",
      "outputs": []
    },
    {
      "id": "2c0a9ea0-4404-4d85-ab4f-9b30ed5b6f2e",
      "cell_type": "markdown",
      "source": "## 1. Análise Exploratória de Dados (EDA)\n\nVamos começar carregando o dataset Fashion MNIST e realizando uma análise exploratória básica para entender melhor os dados.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "1c3396e0-938c-4e59-a0a3-343a25bad7bf",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Carregando o dataset\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n\n# Normalizando os valores dos pixels para o intervalo [0, 1]\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\n# Reshape dos dados para o formato (n_samples, n_features)\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n\n# Print das dimensões dos datasets\nprint('x_train shape:', x_train.shape)\nprint('x_test shape:', x_test.shape)",
      "outputs": []
    },
    {
      "id": "942e7157-ccd4-4ec8-9a3a-be6a36e01a6c",
      "cell_type": "markdown",
      "source": "## 2. Construção e Treinamento do Autoencoder\n\nAgora, vamos construir e treinar o autoencoder. Para isso, vamos definir a arquitetura do modelo, compilar o modelo e, finalmente, treinar o modelo.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "779b517d-5e7c-47e8-9fc1-fb63b0045b2b",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Definindo a dimensão do código codificado\nencoding_dim = 32\n\n# Definindo a camada de entrada\ninput_img = Input(shape=(784,))\n\n# Definindo a camada de codificação\nencoded = Dense(encoding_dim, activation='relu')(input_img)\n\n# Definindo a camada de decodificação\ndecoded = Dense(784, activation='sigmoid')(encoded)\n\n# Definindo o autoencoder\nautoencoder = Model(input_img, decoded)\n\n# Definindo o codificador\nencoder = Model(input_img, encoded)\n\n# Definindo o decodificador\nencoded_input = Input(shape=(encoding_dim,))\ndecoder_layer = autoencoder.layers[-1]\ndecoder = Model(encoded_input, decoder_layer(encoded_input))\n\n# Compilando o autoencoder\nautoencoder.compile(optimizer='adam', loss='binary_crossentropy')",
      "outputs": []
    },
    {
      "id": "3883ca62-3ae7-45ee-b0ba-fc5c1eedf385",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Treinando o autoencoder\nautoencoder.fit(x_train, x_train,\n                epochs=50,\n                batch_size=256,\n                shuffle=True,\n                validation_data=(x_test, x_test))",
      "outputs": []
    },
    {
      "id": "034edd04-ab29-4b3f-9ff3-6d541da35b1b",
      "cell_type": "markdown",
      "source": "## 3. Visualização do Resultado do Decoder\n\nAgora que o autoencoder foi treinado, vamos visualizar o resultado do decoder. Para isso, vamos codificar e decodificar algumas imagens do conjunto de teste e comparar as imagens originais com as imagens reconstruídas.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "68c62b79-c0db-473c-bc7b-0fa198dc99b8",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Codificando e decodificando algumas imagens do conjunto de teste\nencoded_imgs = encoder.predict(x_test)\ndecoded_imgs = decoder.predict(encoded_imgs)\n\n# Plotando as imagens originais e as imagens reconstruídas\nn = 10  # número de imagens para exibir\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # imagens originais\n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # imagens reconstruídas\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()",
      "outputs": []
    },
    {
      "id": "2880cd26-a9db-4789-98d5-2aec83afbbdb",
      "cell_type": "markdown",
      "source": "## 4. Construção e Comparação de Classificadores RandomForest e XgBoost\n\nVamos agora construir dois classificadores, um usando o algoritmo RandomForest e outro usando o algoritmo XgBoost. Depois de treinados, vamos comparar o desempenho de ambos.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "f3051889-a365-4430-9d97-a1277dcc684e",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Construindo e treinando o classificador RandomForest\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED)\nrf_classifier.fit(x_train, y_train)\n\n# Avaliando o classificador RandomForest\nrf_predictions = rf_classifier.predict(x_test)\nprint('RandomForest Classifier:\n', classification_report(y_test, rf_predictions))\n\n# Construindo e treinando o classificador XgBoost\nxgb_classifier = XGBClassifier(random_state=RANDOM_SEED)\nxgb_classifier.fit(x_train, y_train)\n\n# Avaliando o classificador XgBoost\nxgb_predictions = xgb_classifier.predict(x_test)\nprint('XgBoost Classifier:\n', classification_report(y_test, xgb_predictions))",
      "outputs": []
    },
    {
      "id": "90797629-211f-4b56-ae72-e9eb4fde3a83",
      "cell_type": "markdown",
      "source": "## 5. Visualização de Dados com TSNE\n\nVamos agora realizar uma visualização de dados utilizando o algoritmo TSNE. Este algoritmo é útil para visualizar dados de alta dimensão em um espaço de duas ou três dimensões.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "bc13ad08-9a51-4000-ae1b-934e5476cb16",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Reduzindo a dimensionalidade dos dados com TSNE\ntsne = TSNE(n_components=2, random_state=RANDOM_SEED)\nx_test_2D = tsne.fit_transform(x_test)\n\n# Plotando os dados\nplt.figure(figsize=(10, 8))\nscatter = plt.scatter(x_test_2D[:, 0], x_test_2D[:, 1], c=y_test, cmap='viridis')\nplt.colorbar(scatter)\nplt.title('Visualização de Dados com TSNE')\nplt.show()",
      "outputs": []
    },
    {
      "id": "310c1fbf-8580-43e0-bc77-63010bcbf6b2",
      "cell_type": "markdown",
      "source": "## 6. Repetição do Processo com um Autoencoder Convolucional\n\nVamos agora repetir o processo, mas desta vez utilizando um autoencoder convolucional. Os autoencoders convolucionais são especialmente eficazes quando lidamos com imagens.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "447e78c9-4ba7-4404-884b-3afb7bbc8bf7",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Carregando o dataset novamente\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n\n# Normalizando os valores dos pixels para o intervalo [0, 1]\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\n# Adicionando uma dimensão extra para os canais\nx_train = np.expand_dims(x_train, axis=-1)\nx_test = np.expand_dims(x_test, axis=-1)\n\n# Print das dimensões dos datasets\nprint('x_train shape:', x_train.shape)\nprint('x_test shape:', x_test.shape)",
      "outputs": []
    },
    {
      "id": "c05210b1-c76e-4e34-aaeb-3d1544b8c9fc",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Definindo a arquitetura do autoencoder convolucional\ninput_img = Input(shape=(28, 28, 1))\n\nx = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoded = MaxPooling2D((2, 2), padding='same')(x)\n\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(16, (3, 3), activation='relu')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder = Model(input_img, decoded)\nautoencoder.compile(optimizer='adam', loss='binary_crossentropy')",
      "outputs": []
    },
    {
      "id": "6dfcfe02-d68e-4b14-8519-754a4adb473c",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Treinando o autoencoder convolucional\nautoencoder.fit(x_train, x_train,\n                epochs=50,\n                batch_size=256,\n                shuffle=True,\n                validation_data=(x_test, x_test))",
      "outputs": []
    },
    {
      "id": "4c80394a-32e6-4576-9163-4b33ae77c316",
      "cell_type": "markdown",
      "source": "## 7. Comparação dos Resultados (loss) do Autoencoder Simplificado e Convolucional\n\nAgora que treinamos ambos os autoencoders, podemos comparar seus resultados. Para isso, vamos calcular a perda (loss) de ambos os modelos no conjunto de teste.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "649942eb-28ad-4fd4-9652-c6eda79896f1",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Calculando a perda do autoencoder simplificado\nsimplified_autoencoder_loss = autoencoder.evaluate(x_test.reshape(-1, 784), x_test.reshape(-1, 784), verbose=0)\n\n# Calculando a perda do autoencoder convolucional\nconvolutional_autoencoder_loss = autoencoder.evaluate(x_test, x_test, verbose=0)\n\nprint(f'Perda do Autoencoder Simplificado: {simplified_autoencoder_loss}')\nprint(f'Perda do Autoencoder Convolucional: {convolutional_autoencoder_loss}')",
      "outputs": []
    },
    {
      "id": "54a335ce-a1f5-4541-99d4-b0ae61ae072f",
      "cell_type": "markdown",
      "source": "## 8. Utilização da Última Camada de Max Pooling como Feature para um Classificador\n\nVamos agora tentar utilizar a última camada de max pooling do autoencoder convolucional como feature para um classificador. Para isso, vamos extrair as features dessa camada, treinar um classificador com essas features e avaliar o desempenho do classificador.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "9d267ccb-8a03-4975-9b60-de4be6cc1331",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Extraindo as features da última camada de max pooling\nfeature_extractor = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('max_pooling2d_2').output)\nx_train_features = feature_extractor.predict(x_train)\nx_test_features = feature_extractor.predict(x_test)\n\n# Redimensionando as features para o formato (n_samples, n_features)\nx_train_features = x_train_features.reshape((len(x_train_features), np.prod(x_train_features.shape[1:])))\nx_test_features = x_test_features.reshape((len(x_test_features), np.prod(x_test_features.shape[1:])))\n\n# Construindo e treinando o classificador RandomForest com as features extraídas\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED)\nrf_classifier.fit(x_train_features, y_train)\n\n# Avaliando o classificador RandomForest\nrf_predictions = rf_classifier.predict(x_test_features)\nprint('RandomForest Classifier:\n', classification_report(y_test, rf_predictions))",
      "outputs": []
    },
    {
      "id": "7841733a-b48b-496b-87ae-bdfbafd17f7e",
      "cell_type": "markdown",
      "source": "## 9. Visualização de Dados com TSNE (utilizando as features extraídas)\n\nPor fim, vamos realizar novamente uma visualização de dados utilizando o algoritmo TSNE, mas desta vez utilizando as features extraídas da última camada de max pooling do autoencoder convolucional.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "e3409ba6-db56-4594-ab36-494ab93ed968",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Reduzindo a dimensionalidade das features com TSNE\nx_test_features_2D = tsne.fit_transform(x_test_features)\n\n# Plotando os dados\nplt.figure(figsize=(10, 8))\nscatter = plt.scatter(x_test_features_2D[:, 0], x_test_features_2D[:, 1], c=y_test, cmap='viridis')\nplt.colorbar(scatter)\nplt.title('Visualização de Dados com TSNE (utilizando as features extraídas)')\nplt.show()",
      "outputs": []
    }
  ]
}