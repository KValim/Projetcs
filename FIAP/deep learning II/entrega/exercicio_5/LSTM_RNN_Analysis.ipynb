{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "464dcb00-a183-5b9f-84ac-010c8b9ae32b",
        "openai_ephemeral_user_id": "7e6b40a0-fb08-5478-8012-7e0fb23a0c76",
        "openai_subdivision1_iso_code": "BR-SP"
      }
    },
    "noteable": {
      "last_transaction_id": "c5c57c47-a09f-4f43-aa6f-e367d89573c0"
    },
    "selected_hardware_size": "small"
  },
  "cells": [
    {
      "id": "a98103cd-4693-420f-8abb-7f61ac96fd31",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "",
      "outputs": []
    },
    {
      "id": "eb599a46-7698-45db-9a02-9cf5725f8617",
      "cell_type": "markdown",
      "source": "# Análise de Séries Temporais com Redes Neurais Recorrentes\n\nNeste notebook, vamos construir uma Rede Neural Recorrente (RNN) do tipo LSTM (Long Short-Term Memory) para analisar três conjuntos de dados de séries temporais:\n\n- Alcohol_Sales.csv\n- Miles_Traveled.csv\n- BeerWineLiquor.csv\n\nVamos começar importando as bibliotecas necessárias e carregando os conjuntos de dados.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "1c58bf80-88ba-4ebf-ade0-ef10e8f3b0e6",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, SimpleRNN, GRU\nfrom keras.callbacks import ModelCheckpoint\n\n# Carregar os conjuntos de dados\nalcohol_sales = pd.read_csv('Alcohol_Sales.csv')\nmiles_traveled = pd.read_csv('Miles_Traveled.csv')\nbeer_wine_liquor = pd.read_csv('BeerWineLiquor.csv')",
      "outputs": []
    },
    {
      "id": "78515cb7-024f-44c8-ae3f-ed21d150e66f",
      "cell_type": "markdown",
      "source": "## Análise Exploratória de Dados (EDA)\n\nVamos realizar uma análise exploratória básica para entender melhor nossos conjuntos de dados.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "7c125e70-dcee-4609-a30a-5cf6440aaa51",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Verificar as primeiras linhas de cada conjunto de dados\nprint('Alcohol Sales:')\nprint(alcohol_sales.head())\nprint('\\nMiles Traveled:')\nprint(miles_traveled.head())\nprint('\\nBeer, Wine, Liquor:')\nprint(beer_wine_liquor.head())\n\n# Verificar a dimensão de cada conjunto de dados\nprint('\\nShape of the datasets:')\nprint('Alcohol Sales:', alcohol_sales.shape)\nprint('Miles Traveled:', miles_traveled.shape)\nprint('Beer, Wine, Liquor:', beer_wine_liquor.shape)",
      "outputs": []
    },
    {
      "id": "b472fa0d-3ea2-4e95-a63e-e4be74e46c2d",
      "cell_type": "markdown",
      "source": "## Pré-processamento dos Dados\n\nAntes de alimentar os dados para a rede neural, precisamos realizar algumas etapas de pré-processamento. Isso inclui a divisão dos dados em conjuntos de treinamento e teste, a normalização dos dados e a transformação dos dados em um formato adequado para a rede neural.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "96d78015-5c72-4667-8ab6-69c361e5bf1c",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Função para pré-processar os dados\ndef preprocess_data(data, test_size=0.2):\n    # Dividir os dados em conjuntos de treinamento e teste\n    train_data, test_data = train_test_split(data, test_size=test_size, shuffle=False)\n\n    # Normalizar os dados\n    scaler = MinMaxScaler()\n    train_data = scaler.fit_transform(train_data)\n    test_data = scaler.transform(test_data)\n\n    # Transformar os dados para o formato adequado para a rede neural\n    # O formato é (número de amostras, passos de tempo, número de características)\n    train_data = np.reshape(train_data, (train_data.shape[0], 1, train_data.shape[1]))\n    test_data = np.reshape(test_data, (test_data.shape[0], 1, test_data.shape[1]))\n\n    return train_data, test_data, scaler\n\n# Pré-processar os conjuntos de dados\nalcohol_sales_train, alcohol_sales_test, alcohol_sales_scaler = preprocess_data(alcohol_sales)\nmiles_traveled_train, miles_traveled_test, miles_traveled_scaler = preprocess_data(miles_traveled)\nbeer_wine_liquor_train, beer_wine_liquor_test, beer_wine_liquor_scaler = preprocess_data(beer_wine_liquor)",
      "outputs": []
    },
    {
      "id": "b918beb7-85c9-4865-9e16-301c2898a546",
      "cell_type": "markdown",
      "source": "## Construção do Modelo LSTM\n\nAgora que nossos dados estão prontos, podemos construir o modelo LSTM. Vamos criar uma função para isso, para que possamos reutilizá-la para cada conjunto de dados.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "0ebbff22-7093-4768-831b-2598baf65f8a",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Função para construir o modelo LSTM\ndef build_lstm_model(input_shape):\n    model = Sequential()\n    model.add(LSTM(50, activation='relu', input_shape=input_shape))\n    model.add(Dense(1))\n    model.compile(optimizer='adam', loss='mse')\n    return model\n\n# Construir o modelo LSTM para cada conjunto de dados\nalcohol_sales_model = build_lstm_model((1, alcohol_sales_train.shape[2]))\nmiles_traveled_model = build_lstm_model((1, miles_traveled_train.shape[2]))\nbeer_wine_liquor_model = build_lstm_model((1, beer_wine_liquor_train.shape[2]))",
      "outputs": []
    },
    {
      "id": "6363f94a-9b16-46a0-a461-9aef26ef1008",
      "cell_type": "markdown",
      "source": "## Treinamento do Modelo\n\nVamos treinar nossos modelos LSTM. Para cada modelo, vamos usar um callback ModelCheckpoint para salvar o modelo com a menor perda de validação.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "5810db16-2f4c-43c5-bbfc-98baedbbd3c6",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Função para treinar o modelo\ndef train_model(model, train_data, test_data, epochs=10, batch_size=32):\n    # Callback para salvar o modelo com a menor perda de validação\n    checkpoint = ModelCheckpoint('model.h5', save_best_only=True, monitor='val_loss', mode='min')\n\n    # Treinar o modelo\n    history = model.fit(train_data, epochs=epochs, batch_size=batch_size, validation_data=test_data, callbacks=[checkpoint], verbose=0)\n\n    return model, history\n\n# Treinar os modelos LSTM\nalcohol_sales_model, alcohol_sales_history = train_model(alcohol_sales_model, alcohol_sales_train, alcohol_sales_test)\nmiles_traveled_model, miles_traveled_history = train_model(miles_traveled_model, miles_traveled_train, miles_traveled_test)\nbeer_wine_liquor_model, beer_wine_liquor_history = train_model(beer_wine_liquor_model, beer_wine_liquor_train, beer_wine_liquor_test)",
      "outputs": []
    },
    {
      "id": "0f5cdac3-8732-4814-8282-edd636df227b",
      "cell_type": "markdown",
      "source": "## Avaliação do Modelo\n\nApós o treinamento, vamos avaliar o desempenho de nossos modelos. Vamos plotar a perda de treinamento e validação ao longo das épocas e também calcular o erro quadrático médio (MSE) no conjunto de teste.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "04888729-2685-4ddd-b365-53cfd44ac806",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Função para plotar a perda de treinamento e validação\ndef plot_loss(history):\n    plt.figure(figsize=(10, 6))\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper right')\n    plt.show()\n\n# Função para calcular o MSE\ndef calculate_mse(model, test_data):\n    predictions = model.predict(test_data)\n    mse = np.mean((predictions - test_data)**2)\n    return mse\n\n# Avaliar os modelos LSTM\nprint('Alcohol Sales Model:')\nplot_loss(alcohol_sales_history)\nprint('MSE:', calculate_mse(alcohol_sales_model, alcohol_sales_test))\n\nprint('\\nMiles Traveled Model:')\nplot_loss(miles_traveled_history)\nprint('MSE:', calculate_mse(miles_traveled_model, miles_traveled_test))\n\nprint('\\nBeer, Wine, Liquor Model:')\nplot_loss(beer_wine_liquor_history)\nprint('MSE:', calculate_mse(beer_wine_liquor_model, beer_wine_liquor_test))",
      "outputs": []
    },
    {
      "id": "deaab1c0-2110-42c7-8610-47cd6570bcdc",
      "cell_type": "markdown",
      "source": "## Comparação com Modelos Simples de RNN e GRU\n\nVamos comparar o desempenho de nossos modelos LSTM com modelos de RNN simples e GRU. Para isso, vamos construir e treinar esses modelos para cada conjunto de dados.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "d67aa432-7bf1-40d5-bbcf-91b20837a7a2",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Função para construir o modelo SimpleRNN\ndef build_simplernn_model(input_shape):\n    model = Sequential()\n    model.add(SimpleRNN(50, activation='relu', input_shape=input_shape))\n    model.add(Dense(1))\n    model.compile(optimizer='adam', loss='mse')\n    return model\n\n# Função para construir o modelo GRU\ndef build_gru_model(input_shape):\n    model = Sequential()\n    model.add(GRU(50, activation='relu', input_shape=input_shape))\n    model.add(Dense(1))\n    model.compile(optimizer='adam', loss='mse')\n    return model\n\n# Construir os modelos SimpleRNN e GRU para cada conjunto de dados\nalcohol_sales_simplernn_model = build_simplernn_model((1, alcohol_sales_train.shape[2]))\nalcohol_sales_gru_model = build_gru_model((1, alcohol_sales_train.shape[2]))\n\nmiles_traveled_simplernn_model = build_simplernn_model((1, miles_traveled_train.shape[2]))\nmiles_traveled_gru_model = build_gru_model((1, miles_traveled_train.shape[2]))\n\nbeer_wine_liquor_simplernn_model = build_simplernn_model((1, beer_wine_liquor_train.shape[2]))\nbeer_wine_liquor_gru_model = build_gru_model((1, beer_wine_liquor_train.shape[2]))",
      "outputs": []
    },
    {
      "id": "9bc6a9db-41d0-4bd7-9b24-f07e4b770b0f",
      "cell_type": "markdown",
      "source": "## Comparação com Modelos ARIMA e SARIMA\n\nFinalmente, vamos comparar o desempenho de nossos modelos de redes neurais com modelos clássicos de séries temporais, como ARIMA e SARIMA. Para isso, vamos construir e treinar esses modelos para cada conjunto de dados.",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "9e74d3ab-a0db-4815-8ea4-06f620426729",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "# Função para construir e treinar o modelo ARIMA\ndef build_arima_model(data, order):\n    model = ARIMA(data, order=order)\n    model_fit = model.fit(disp=0)\n    return model_fit\n\n# Função para construir e treinar o modelo SARIMA\ndef build_sarima_model(data, order, seasonal_order):\n    model = SARIMAX(data, order=order, seasonal_order=seasonal_order)\n    model_fit = model.fit(disp=0)\n    return model_fit\n\n# Construir e treinar os modelos ARIMA e SARIMA para cada conjunto de dados\nalcohol_sales_arima_model = build_arima_model(alcohol_sales_train, (5,1,0))\nalcohol_sales_sarima_model = build_sarima_model(alcohol_sales_train, (5,1,0), (1,1,1,12))\n\nmiles_traveled_arima_model = build_arima_model(miles_traveled_train, (5,1,0))\nmiles_traveled_sarima_model = build_sarima_model(miles_traveled_train, (5,1,0), (1,1,1,12))\n\nbeer_wine_liquor_arima_model = build_arima_model(beer_wine_liquor_train, (5,1,0))\nbeer_wine_liquor_sarima_model = build_sarima_model(beer_wine_liquor_train, (5,1,0), (1,1,1,12))",
      "outputs": []
    }
  ]
}