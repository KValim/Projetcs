{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d7303d41-7ab2-4298-bbda-775a5366ab25",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "# Projeto de Classificação de Frutas\n",
        "\n",
        "Este notebook contém um projeto de classificação de frutas utilizando uma Rede Neural Convolucional (CNN). O objetivo é identificar diferentes tipos de frutas a partir de imagens. O modelo será treinado a partir do zero, sem o uso de modelos pré-treinados.\n",
        "\n",
        "## Instruções Gerais\n",
        "\n",
        "1. Utilizaremos a LetNet-5 como exemplo inicial, bem como o exemplo visto em sala de aula do dataset MNIST.\n",
        "2. Iniciaremos o trabalho com parte do dataset e iremos adicionando gradativamente mais tipos distintos de frutos.\n",
        "3. É permitido usar outras abordagens e arquiteturas.\n",
        "4. É permitido o uso de Autoencoders.\n",
        "5. É obrigatório o uso de CNN.\n",
        "6. É permitido o uso de técnicas de processamento de imagens.\n",
        "7. Não é permitido o uso de modelos pré-treinados.\n",
        "8. Faremos uma boa distribuição dos dados de teste, treinamento e validação.\n",
        "\n",
        "## Instruções Adicionais\n",
        "\n",
        "1. Criaremos algumas visualizações após o treinamento do modelo.\n",
        "2. Separaremos bem as células.\n",
        "3. Criaremos uma etapa de Análise Exploratória de Dados (EDA) básica.\n",
        "4. Comentaremos o código devidamente e criaremos markdowns explicativos.\n",
        "\n",
        "Todas as predições não podem possuir lags de predição, poucos lags são permitidos."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "bba6d339-3470-4d17-82ed-b9b95ae59cf5",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "## Importação das Bibliotecas\n",
        "\n",
        "Primeiro, vamos importar todas as bibliotecas necessárias para o projeto. Isso inclui bibliotecas para manipulação de dados, visualização de dados, manipulação de imagens, construção e treinamento do modelo de CNN, entre outros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "98a9d469-6fcd-410a-9336-c8b7c6970d3b",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "\n",
        "# Biblioteca para manipulação de arrays\n",
        "import numpy as np\n",
        "\n",
        "# Biblioteca para manipulação de dados em formato de tabela\n",
        "import pandas as pd\n",
        "\n",
        "# Biblioteca para visualização de dados\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Biblioteca para manipulação de imagens\n",
        "import cv2\n",
        "\n",
        "# Biblioteca para manipulação de arquivos e diretórios\n",
        "import os\n",
        "\n",
        "# Biblioteca para divisão de dados em treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Bibliotecas do Keras para construção e treinamento do modelo de CNN\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Biblioteca para visualização da matriz de confusão\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Biblioteca para visualização de gráficos interativos\n",
        "import seaborn as sns"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b676d05b-98c5-4310-9b91-799cb6c8138c",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "## Definição do Diretório das Imagens\n",
        "\n",
        "Vamos definir o caminho do diretório onde estão armazenadas as imagens das frutas que serão utilizadas para treinar nosso modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d9e29c78-8701-4741-b9ae-58cf2db1ef21",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "# Definindo o caminho do diretório das imagens\n",
        "image_directory = 'fruits/fruits-360_dataset/fruits-360/Training/'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "13c3f9a1-efab-4a4a-aa4a-7dd30ab6c839",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "## Análise Exploratória de Dados (EDA)\n",
        "\n",
        "Antes de começarmos a construir nosso modelo, vamos realizar uma análise exploratória básica dos dados. Isso nos ajudará a entender melhor os dados com os quais estamos trabalhando e a tomar decisões mais informadas ao construir nosso modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "cac2073b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número total de classes de frutas: 120\n",
            "Primeiras 5 classes de frutas: ['Apple Braeburn', 'Apple Crimson Snow', 'Apple Golden 1', 'Apple Golden 2', 'Apple Golden 3']\n"
          ]
        }
      ],
      "source": [
        "# Listando os diretórios presentes no diretório de imagens\n",
        "# Cada diretório representa uma classe de fruta\n",
        "fruit_classes = os.listdir(image_directory)\n",
        "\n",
        "# Imprimindo o número total de classes de frutas\n",
        "print('Número total de classes de frutas:', len(fruit_classes))\n",
        "\n",
        "# Imprimindo as primeiras 5 classes de frutas\n",
        "print('Primeiras 5 classes de frutas:', fruit_classes[:5])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7eef5f7d-e69b-4885-b7ea-38af5c85ee1b",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "## Preparação dos Dados\n",
        "\n",
        "Agora que temos uma compreensão básica dos dados, vamos prepará-los para o treinamento do modelo. Isso inclui a leitura das imagens, a conversão das imagens em arrays, a normalização dos valores dos pixels e a divisão dos dados em conjuntos de treinamento, validação e teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "17f363b0-46c9-4b57-8380-a3b9d66c9ae1",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Grape White 4' 'Guava' 'Apple Golden 3' 'Lemon Meyer' 'Cherry 1'\n",
            " 'Mulberry' 'Papaya' 'Apple Red Delicious' 'Grape Pink' 'Salak'\n",
            " 'Banana Red' 'Maracuja' 'Apple Red Yellow 1' 'Eggplant' 'Physalis'\n",
            " 'Pineapple' 'Strawberry Wedge' 'Apple Braeburn' 'Pepper Yellow'\n",
            " 'Rambutan' 'Nectarine' 'Grapefruit Pink' 'Cherry Wax Yellow'\n",
            " 'Onion Red Peeled' 'Grape White 2' 'Apple Red Yellow 2' 'Avocado ripe'\n",
            " 'Tomato 3' 'Peach 2' 'Pomegranate']\n"
          ]
        }
      ],
      "source": [
        "# Inicializando listas para armazenar as imagens e os rótulos\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Definindo o tamanho das imagens\n",
        "image_size = 100\n",
        "\n",
        "# Escolhendo 30 classes de frutas aleatoriamente\n",
        "np.random.seed(42)\n",
        "selected_classes = np.random.choice(fruit_classes, 30, replace=False)\n",
        "\n",
        "print(selected_classes)\n",
        "\n",
        "# Lendo as imagens e associando a seus respectivos rótulos\n",
        "for i in selected_classes:\n",
        "    path = os.path.join(image_directory, i)\n",
        "    for img in os.listdir(path):\n",
        "        img_array = cv2.imread(os.path.join(path, img))\n",
        "        img_array = cv2.resize(img_array, (image_size, image_size))\n",
        "        images.append(img_array)\n",
        "        labels.append(i)\n",
        "\n",
        "# Convertendo as listas de imagens e rótulos em arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Normalizando os valores dos pixels das imagens\n",
        "images = images.astype('float32')/255.0\n",
        "\n",
        "# Dividindo os dados em conjuntos de treinamento, validação e teste\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7d1a5af4-2bfb-4c23-bb21-8a0038488a3b",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "## Construção do Modelo\n",
        "\n",
        "Agora que nossos dados estão preparados, podemos começar a construir nosso modelo de CNN. Vamos usar a arquitetura LeNet-5 como base, mas sinta-se à vontade para experimentar outras arquiteturas se desejar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0afb5299-c440-4d8e-8604-c6262359d59a",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 98, 98, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 49, 49, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 47, 47, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 23, 23, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 21, 21, 64)        36928     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 28224)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                1806400   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 120)               7800      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,870,520\n",
            "Trainable params: 1,870,520\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Construindo o modelo\n",
        "model = Sequential()\n",
        "\n",
        "# Adicionando a primeira camada de convolução\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_size, image_size, 3)))\n",
        "\n",
        "# Adicionando a primeira camada de pooling\n",
        "model.add(MaxPool2D((2, 2)))\n",
        "\n",
        "# Adicionando a segunda camada de convolução\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Adicionando a segunda camada de pooling\n",
        "model.add(MaxPool2D((2, 2)))\n",
        "\n",
        "# Adicionando a terceira camada de convolução\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Adicionando a camada de achatamento para conectar a CNN com a camada densa\n",
        "model.add(Flatten())\n",
        "\n",
        "# Adicionando a primeira camada densa\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Adicionando a camada de saída\n",
        "model.add(Dense(len(fruit_classes), activation='softmax'))\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Imprimindo o resumo do modelo\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2fb7b810-6758-47cd-80ed-664882548794",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "## Treinamento do Modelo\n",
        "\n",
        "Com o modelo construído, podemos agora treiná-lo usando nossos dados de treinamento. Também vamos usar nossos dados de validação para validar o desempenho do modelo durante o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ec4cd9b7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 12018 images belonging to 30 classes.\n",
            "Found 2994 images belonging to 30 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras import preprocessing\n",
        "\n",
        "train_datagen = preprocessing.image.ImageDataGenerator(validation_split=0.20)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'fruits/fruits-360_dataset/fruits-360/Training_30_fruits',\n",
        "    batch_size=200,\n",
        "    color_mode='rgb',\n",
        "    subset='training',\n",
        "    target_size=(30, 30)\n",
        "    )\n",
        "\n",
        "valid_generator = train_datagen.flow_from_directory(\n",
        "    'fruits/fruits-360_dataset/fruits-360/Training_30_fruits',\n",
        "    batch_size=200,\n",
        "    color_mode = 'rgb',\n",
        "    subset='validation',\n",
        "    target_size=(30, 30)\n",
        "    )\n",
        "\n",
        "x,y = train_generator.next()\n",
        "num_classes = y[0].shape[0]\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "87933ae1-6432-429a-83d7-40a1e8044e99",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Temp\\ipykernel_22652\\1327922180.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_generator,\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node 'sequential_1/flatten_1/Reshape' defined at (most recent call last):\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1041, in launch_instance\n      app.start()\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 595, in run_forever\n      self._run_once()\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1881, in _run_once\n      handle._run()\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Temp\\ipykernel_22652\\1327922180.py\", line 5, in <module>\n      history = model.fit_generator(train_generator,\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2507, in fit_generator\n      return self.fit(\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\reshaping\\flatten.py\", line 104, in call\n      return tf.reshape(inputs, flattened_shape)\nNode: 'sequential_1/flatten_1/Reshape'\nInput to reshape is a tensor with 204800 values, but the requested shape requires a multiple of 28224\n\t [[{{node sequential_1/flatten_1/Reshape}}]] [Op:__inference_train_function_2075]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\KAIQUEHENRIQUEVALIM\\Documents\\GitHub\\Projetcs\\FIAP\\deep learning II\\entrega\\exercicio_6\\fruits_refactored.ipynb Célula 14\u001b[0m in \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KAIQUEHENRIQUEVALIM/Documents/GitHub/Projetcs/FIAP/deep%20learning%20II/entrega/exercicio_6/fruits_refactored.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Treinando o modelo\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KAIQUEHENRIQUEVALIM/Documents/GitHub/Projetcs/FIAP/deep%20learning%20II/entrega/exercicio_6/fruits_refactored.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m mcp_save \u001b[39m=\u001b[39m ModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39mmodel_best.h5\u001b[39m\u001b[39m'\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, mode\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, save_weights_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/KAIQUEHENRIQUEVALIM/Documents/GitHub/Projetcs/FIAP/deep%20learning%20II/entrega/exercicio_6/fruits_refactored.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(train_generator, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KAIQUEHENRIQUEVALIM/Documents/GitHub/Projetcs/FIAP/deep%20learning%20II/entrega/exercicio_6/fruits_refactored.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                     steps_per_epoch\u001b[39m=\u001b[39;49mSTEP_SIZE_TRAIN,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KAIQUEHENRIQUEVALIM/Documents/GitHub/Projetcs/FIAP/deep%20learning%20II/entrega/exercicio_6/fruits_refactored.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mvalid_generator,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KAIQUEHENRIQUEVALIM/Documents/GitHub/Projetcs/FIAP/deep%20learning%20II/entrega/exercicio_6/fruits_refactored.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                     validation_steps\u001b[39m=\u001b[39;49mSTEP_SIZE_VALID,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KAIQUEHENRIQUEVALIM/Documents/GitHub/Projetcs/FIAP/deep%20learning%20II/entrega/exercicio_6/fruits_refactored.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[mcp_save])\n",
            "File \u001b[1;32mc:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:2507\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2495\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2496\u001b[0m \n\u001b[0;32m   2497\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2498\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2499\u001b[0m \u001b[39m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2500\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2501\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2502\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2503\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2504\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2505\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   2506\u001b[0m )\n\u001b[1;32m-> 2507\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   2508\u001b[0m     generator,\n\u001b[0;32m   2509\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   2510\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   2511\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2512\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   2513\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   2514\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   2515\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   2516\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2517\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   2518\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   2519\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   2520\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   2521\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m   2522\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_1/flatten_1/Reshape' defined at (most recent call last):\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1041, in launch_instance\n      app.start()\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 595, in run_forever\n      self._run_once()\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1881, in _run_once\n      handle._run()\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Temp\\ipykernel_22652\\1327922180.py\", line 5, in <module>\n      history = model.fit_generator(train_generator,\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2507, in fit_generator\n      return self.fit(\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\KAIQUEHENRIQUEVALIM\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\reshaping\\flatten.py\", line 104, in call\n      return tf.reshape(inputs, flattened_shape)\nNode: 'sequential_1/flatten_1/Reshape'\nInput to reshape is a tensor with 204800 values, but the requested shape requires a multiple of 28224\n\t [[{{node sequential_1/flatten_1/Reshape}}]] [Op:__inference_train_function_2075]"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Treinando o modelo\n",
        "mcp_save = ModelCheckpoint('model_best.h5', monitor='val_accuracy', mode= 'auto', save_weights_only=True, save_best_only=True, verbose =1)\n",
        "history = model.fit_generator(train_generator, \n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=10, callbacks=[mcp_save])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6ebf838c-7230-4359-8772-a2555338566a",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "## Avaliação do Modelo\n",
        "\n",
        "Após o treinamento, vamos avaliar o desempenho do nosso modelo usando os dados de teste. Isso nos dará uma ideia de como o modelo se sairá ao classificar imagens de frutas que não viu durante o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a413ed5-83a0-45ce-b310-371f3027f624",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "# Avaliando o modelo\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Imprimindo a acurácia do modelo\n",
        "print('Acurácia do modelo:', accuracy)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7a3b3990-a9d4-466a-ae08-35698d4ddbb0",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "## Visualização dos Resultados\n",
        "\n",
        "Finalmente, vamos visualizar os resultados do nosso modelo. Isso inclui a visualização da matriz de confusão para entender melhor onde o modelo está cometendo erros, bem como a visualização das curvas de perda e acurácia durante o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50520569-2822-451c-8698-f0868d58522f",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "# Fazendo previsões com o modelo\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convertendo as previsões em rótulos\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Criando a matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "\n",
        "# Visualizando a matriz de confusão\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32b157cd-d635-4d0c-bab9-5e49cc22aa17",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [],
      "source": [
        "# Plotando as curvas de perda e acurácia durante o treinamento\n",
        "\n",
        "# Definindo o tamanho da figura\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Subplot 1: curva de perda\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Perda (treinamento)')\n",
        "plt.plot(history.history['val_loss'], label='Perda (validação)')\n",
        "plt.title('Perda do Modelo durante o Treinamento')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Perda')\n",
        "plt.legend()\n",
        "\n",
        "# Subplot 2: curva de acurácia\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Acurácia (treinamento)')\n",
        "plt.plot(history.history['val_accuracy'], label='Acurácia (validação)')\n",
        "plt.title('Acurácia do Modelo durante o Treinamento')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend()\n",
        "\n",
        "# Mostrando a figura\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "noteable": {
      "last_transaction_id": "91de2712-d511-4604-a737-78cec8516eb7"
    },
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "ce748637-5086-556c-a846-d47c86588f6f",
        "openai_ephemeral_user_id": "7e6b40a0-fb08-5478-8012-7e0fb23a0c76",
        "openai_subdivision1_iso_code": "BR-SP"
      }
    },
    "selected_hardware_size": "small"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
